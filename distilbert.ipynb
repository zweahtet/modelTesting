{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Question Answering Distilbert Model\n",
    "- https://huggingface.co/distilbert-base-cased-distilled-squad\n",
    "- https://www.kaggle.com/code/jamesmcguigan/coleridge-huggingface-question-answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = r\"\"\"Chapter 17.5. Lead and Copper, \n",
    "Article 7. Public Education Program for Lead Action Level Exceedances, \n",
    "§ 64690.80. Recordkeeping. Any system subject to the requirements of this \n",
    "chapter shall retain on its premises original records of all sampling data \n",
    "and analyses, reports, surveys, letters, evaluations, schedules, Department \n",
    "determinations, and any other information required by this chapter. Each water \n",
    "system shall retain the records required by this section for no fewer than 12 \n",
    "years or two compliance cycles (as defined in Section 64400.20), whichever is longer.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'Each water \n",
      "system', score: 0.0354, start: 400, end: 418\n"
     ]
    }
   ],
   "source": [
    "result = question_answerer(question=\"what water system?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "questions = [\"What are California water regulations?\", \"How do California water regulations impact agriculture?\"]\n",
    "passages = [\"California water regulations are laws that govern how water is used and managed in California.\",            \"California water regulations can have a significant impact on agriculture, which is a major water user in the state.\"]\n",
    "answers = [(\"laws that govern how water is used and managed\", \"California water regulations\"),           (\"have a significant impact on agriculture\", \"California water regulations\")]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "inputs = tokenizer(questions, passages, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "start_positions = torch.tensor([tokenizer.encode(answers[i][0], add_special_tokens=False)[0] for i in range(len(answers))])\n",
    "end_positions = torch.tensor([tokenizer.encode(answers[i][1], add_special_tokens=False)[-1] for i in range(len(answers))])\n",
    "inputs.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**inputs)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'distilbert_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, Trainer, TrainingArguments, default_data_collator\n",
    "from transformers.data.processors.squad import SquadExample, SquadV1Processor\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_data(context, question, answer):\n",
    "    encoded_dict = tokenizer.encode_plus(question, context, return_offsets_mapping=True, max_length=512, padding=\"max_length\", truncation=True)\n",
    "    start_char = encoded_dict[\"offset_mapping\"][encoded_dict[\"input_ids\"].index(tokenizer.sep_token_id)][0]\n",
    "    end_char = start_char + len(answer)\n",
    "    return SquadExample(\n",
    "        qas_id=\"\",\n",
    "        question_text=question,\n",
    "        context_text=context,\n",
    "        answer_text=answer,\n",
    "        start_position_character=start_char,\n",
    "        end_position_character=end_char,\n",
    "        is_impossible=False\n",
    "    )\n",
    "\n",
    "# Convert the data to features\n",
    "train_examples = []\n",
    "for row in df.itertuples():\n",
    "    train_examples.append(tokenize_data(row.context, row.question, row.answer))\n",
    "\n",
    "processor = SquadV1Processor()\n",
    "train_features = processor.convert_examples_to_features(train_examples, tokenizer, max_length=512, doc_stride=128, padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Load the pre-trained model and fine-tune on the data\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    disable_tqdm=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_features,\n",
    "    data_collator=default_data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "model.load_state_dict(torch.load('distilbert_model.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Accuracy: 0.0\n",
      "End Accuracy: 0.0\n",
      "F1 Score: nan\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "    start_preds = torch.argmax(start_logits, dim=1)\n",
    "    end_preds = torch.argmax(end_logits, dim=1)\n",
    "    start_acc = (start_preds == start_positions).float().mean()\n",
    "    end_acc = (end_preds == end_positions).float().mean()\n",
    "    f1_score = 2 * ((start_acc * end_acc) / (start_acc + end_acc))\n",
    "\n",
    "print(\"Start Accuracy:\", start_acc.item())\n",
    "print(\"End Accuracy:\", end_acc.item())\n",
    "print(\"F1 Score:\", f1_score.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS SageMaker Training Job\n",
    "This section requires training-job/ml.p3.2xlarge GPU instance, which is not included in our free 2 months subscription. When training on the finalized large dataset, we need to use this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "role = iam_client.get_role(RoleName='AmazonSageMaker-ExecutionRole-20230307T225001')['Role']['Arn']\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2023-03-14-23-15-25-396\n"
     ]
    },
    {
     "ename": "ResourceLimitExceeded",
     "evalue": "An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The requested resource training-job/ml.p3.2xlarge is not available in this region",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceLimitExceeded\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 28\u001b[0m\n\u001b[0;32m     14\u001b[0m huggingface_estimator \u001b[39m=\u001b[39m HuggingFace(\n\u001b[0;32m     15\u001b[0m \tentry_point\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrun_clm.py\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m \tsource_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./examples/pytorch/language-modeling\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \thyperparameters \u001b[39m=\u001b[39m hyperparameters\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[39m# starting the train job\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m huggingface_estimator\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[1;32mc:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\sagemaker\\workflow\\pipeline_context.py:272\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[39mreturn\u001b[39;00m context\n\u001b[0;32m    270\u001b[0m     \u001b[39mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 272\u001b[0m \u001b[39mreturn\u001b[39;00m run_func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\sagemaker\\estimator.py:1153\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[1;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_for_training(job_name\u001b[39m=\u001b[39mjob_name)\n\u001b[0;32m   1152\u001b[0m experiment_config \u001b[39m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[1;32m-> 1153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_training_job \u001b[39m=\u001b[39m _TrainingJob\u001b[39m.\u001b[39;49mstart_new(\u001b[39mself\u001b[39;49m, inputs, experiment_config)\n\u001b[0;32m   1154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjobs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_training_job)\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m wait:\n",
      "File \u001b[1;32mc:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\sagemaker\\estimator.py:2085\u001b[0m, in \u001b[0;36m_TrainingJob.start_new\u001b[1;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[0;32m   2060\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create a new Amazon SageMaker training job from the estimator.\u001b[39;00m\n\u001b[0;32m   2061\u001b[0m \n\u001b[0;32m   2062\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2081\u001b[0m \u001b[39m    all information about the started training job.\u001b[39;00m\n\u001b[0;32m   2082\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2083\u001b[0m train_args \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_train_args(estimator, inputs, experiment_config)\n\u001b[1;32m-> 2085\u001b[0m estimator\u001b[39m.\u001b[39msagemaker_session\u001b[39m.\u001b[39mtrain(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_args)\n\u001b[0;32m   2087\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(estimator\u001b[39m.\u001b[39msagemaker_session, estimator\u001b[39m.\u001b[39m_current_job_name)\n",
      "File \u001b[1;32mc:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\sagemaker\\session.py:654\u001b[0m, in \u001b[0;36mSession.train\u001b[1;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, training_image_config, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[0;32m    651\u001b[0m     LOGGER\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mtrain request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, json\u001b[39m.\u001b[39mdumps(request, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m))\n\u001b[0;32m    652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_client\u001b[39m.\u001b[39mcreate_training_job(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrequest)\n\u001b[1;32m--> 654\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intercept_create_request(train_request, submit, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\sagemaker\\session.py:4813\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[1;34m(self, request, create, func_name)\u001b[0m\n\u001b[0;32m   4800\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_intercept_create_request\u001b[39m(\n\u001b[0;32m   4801\u001b[0m     \u001b[39mself\u001b[39m, request: typing\u001b[39m.\u001b[39mDict, create, func_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[0;32m   4802\u001b[0m ):\n\u001b[0;32m   4803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[0;32m   4804\u001b[0m \n\u001b[0;32m   4805\u001b[0m \u001b[39m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4811\u001b[0m \u001b[39m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[0;32m   4812\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4813\u001b[0m     \u001b[39mreturn\u001b[39;00m create(request)\n",
      "File \u001b[1;32mc:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\sagemaker\\session.py:652\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[1;34m(request)\u001b[0m\n\u001b[0;32m    650\u001b[0m LOGGER\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mCreating training-job with name: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, job_name)\n\u001b[0;32m    651\u001b[0m LOGGER\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mtrain request: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, json\u001b[39m.\u001b[39mdumps(request, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m))\n\u001b[1;32m--> 652\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msagemaker_client\u001b[39m.\u001b[39mcreate_training_job(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\botocore\\client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[0;32m    529\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\zachz\\Documents\\GitHub\\modelTesting\\venv\\lib\\site-packages\\botocore\\client.py:960\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    958\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    959\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m--> 960\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m    961\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mResourceLimitExceeded\u001b[0m: An error occurred (ResourceLimitExceeded) when calling the CreateTrainingJob operation: The requested resource training-job/ml.p3.2xlarge is not available in this region"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "hyperparameters = {\n",
    "\t'model_name_or_path':'gpt2',\n",
    "\t'output_dir':'/opt/ml/model'\n",
    "\t# add your remaining hyperparameters\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.17.0/examples/pytorch/language-modeling\n",
    "}\n",
    "\n",
    "# git configuration to download our fine-tuning script\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.17.0'}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "\tentry_point='run_clm.py',\n",
    "\tsource_dir='./examples/pytorch/language-modeling',\n",
    "\tinstance_type='ml.p3.2xlarge',\n",
    "\tinstance_count=1,\n",
    "\trole=role,\n",
    "\tgit_config=git_config,\n",
    "\ttransformers_version='4.17.0',\n",
    "\tpytorch_version='1.10.2',\n",
    "\tpy_version='py38',\n",
    "\thyperparameters = hyperparameters\n",
    ")\n",
    "\n",
    "# starting the train job\n",
    "huggingface_estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
